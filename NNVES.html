<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Neural Network Verification by Exploiting Sparsity</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title"></a>
				<nav>
					<ul>
						<li><a href="index.html#intro">About</a></li>
						<li><a href="index.html#one">Portfolio</a></li>
						<li><a href="index.html#two">Publications</a></li>
						<li><a href="index.html#three">Contact</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Neural Network Verification by Exploiting Sparsity</h1>
                            <a href="https://github.com/M-attNewton/NNPsatzSparse">GitHub</a>, 
                            <a href="https://www.sciencedirect.com/science/article/pii/S0005109823003941">Paper</a>
							<!--<span class="image fit"><img src="images/pic04.jpg" alt="" /></span>-->
                            <h2>Motivation</h2>
							<ul>
                                <li>Neural networks are more widespread and obtain robustness guarantees for them are important, especially in safety-critical applications.</li>
                                <li>A trained neural network’s sensitivity to adversarial attacks is one of its greatest shortcomings.</li>
                            </ul>
                            <h2>Contribution</h2>
                            <ul>
                                <li>Neural network is written as a set of equality and inequality constraints from bounds on the non-linear activation functions.</li>
                                <li>Approaching the problem from a different perspective, use sparse polynomial optimisation theory and Positivstellensatz, a key result in real algebraic geometry.</li>
                                <li>Exploit the natural cascading structure of the neural network using ideas from chordal sparsity and semi-definite programming.</li>
                            </ul>
                            <span class="image fit"><img src="images/project/5by20SparsityCE.png" alt="" /></span>
                            <p class="caption">The sparsity pattern of the constraint matrix for a twenty-layer neural network with five hidden units in each layer.</p>
                            <span class="image fit"><img src="images/project/bigCSP.png" alt="" /></span>
                            <p class="caption">Diagram of a neural network showing how it is broken down by its natural cascading structure.</p>
                            <h2>Analysis</h2>
                            <ul>
                                <li>The Positivstellensatz provides a trade-off between conservativeness and complexity within the optimisation problem.</li>
                                <li>Scalability of the method is drastically improved as the constraint matrices are broken down into smaller constraint matrices.</li>
                            </ul>
                            <h2>Results</h2>
                            <ul>
                                <li>Numerical examples show that bounds can be tightened significantly, over state-of-the-art approaches.</li>
                                <li>The computational time to solve the optimisation problem against similar approaches is improved.</li>
                                <li>Compare the solve times of different solvers and show how accuracy can be improved at the expense of increased computation time.</li>
                            </ul>
                            <span class="image fit"><img src="images/project/2NodesVaryLayersRelu.png" alt="" /></span>
                            <p class="caption">Comparing the computational time of different approaches for a neural network with two nodes in each layer and a varying number of layers.</p>
                            <span class="image fit"><img src="images/project/2by8by5by2Relu.png" alt="" /></span>
                            <p class="caption">Comparing the accuracy of different approaches to the true values of the neural network’s output.</p>
                        </div>
					</section>

			</div>

		<!-- Footer -->
            <footer id="footer" class="wrapper style1-alt">
                <div class="inner">
                    <ul class="menu">
                        <li>&copy; Matthew Newton 2024. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    </ul>
                </div>
            </footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>